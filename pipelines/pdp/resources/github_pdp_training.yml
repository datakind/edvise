resources:
  jobs:
    github_sourced_pdp_training_pipeline:
      name: github_sourced_pdp_training_pipeline
      max_concurrent_runs: 2
      tasks:
        - task_key: data_audit
          spark_python_task:
            python_file: src/edvise/scripts/pdp_data_audit.py
            source: GIT
            parameters:
              - --bronze_volume_path
              - "/Volumes/staging_sst_01/{{job.parameters.databricks_institution_name}}_bronze/bronze_volume"
              - --silver_volume_path
              - "/Volumes/staging_sst_01/{{job.parameters.databricks_institution_name}}_silver/silver_volume"
              - --DB_workspace
              - "{{job.parameters.DB_workspace}}"
              - --config_file_path 
              - "/Volumes/staging_sst_01/{{job.parameters.databricks_institution_name}}_bronze/bronze_volume/training_inputs/{{job.parameters.config_file_name}}"
          existing_cluster_id: 5507-145238-6we6v2w3
          libraries:
            - pypi:
                package: pandas==2.2.3
            - pypi:
                package: faker==33.1.0
            - pypi:
                package: google-cloud-storage==2.19.0
            - pypi:
                package: scikit-learn==1.5.2
            - pypi:
                package: missingno==0.5.2
            - pypi:
                package: tomli==2.2.1
            - pypi:
                package: tomlkit==0.13.3
            - pypi:
                package: pandera==0.23.0
            - pypi:
                package: pydantic~=2.10
        - task_key: feature_generation
            spark_python_task:
              python_file: src/edvise/scripts/pdp_feature_generation.py
              source: GIT
              parameters:
                - --bronze_volume_path
                - "/Volumes/staging_sst_01/{{job.parameters.databricks_institution_name}}_bronze/bronze_volume"
                - --silver_volume_path
                - "/Volumes/staging_sst_01/{{job.parameters.databricks_institution_name}}_silver/silver_volume"
                - --DB_workspace
                - "{{job.parameters.DB_workspace}}"
                - --config_file_path 
                - "/Volumes/staging_sst_01/{{job.parameters.databricks_institution_name}}_bronze/bronze_volume/training_inputs/{{job.parameters.config_file_name}}"
            existing_cluster_id: 5507-145238-6we6v2w3
            libraries:
              - pypi:
                  package: pandas==2.2.3
              - pypi:
                  package: faker==33.1.0
              - pypi:
                  package: google-cloud-storage==2.19.0
              - pypi:
                  package: scikit-learn==1.5.2
              - pypi:
                  package: missingno==0.5.2
              - pypi:
                  package: tomli==2.2.1
              - pypi:
                  package: tomlkit==0.13.3
              - pypi:
                  package: pandera==0.23.0
              - pypi:
                  package: pydantic~=2.10
      git_source:
        git_url: https://github.com/datakind/edvise
        git_provider: gitHub
        git_branch: develop
      tags:
        dev: kayla_wilding
      queue:
        enabled: true
      parameters:
        - name: databricks_institution_name
          default: ${var.databricks_institution_name}
        - name: db_run_id
          default: "{{job.run_id}}"
        - name: DB_workspace
          default: ${var.DB_workspace}
        - name: DK_CC_EMAIL
          default: ${var.datakind_notification_email}
        - name: config_file_name
          default: ${var.config_file_name}
        - name: ds_run_as
          default: ${var.ds_run_as}
        - name: datakind_notification_email
          default: ${var.datakind_notification_email}
      permissions:
        - user_name: ${var.ds_run_as}
          level: IS_OWNER

